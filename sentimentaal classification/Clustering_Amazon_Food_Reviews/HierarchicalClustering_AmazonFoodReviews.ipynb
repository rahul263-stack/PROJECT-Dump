{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering on Amazon Food Reviews\n",
    "Data Source: https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "\n",
    "The Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon.\n",
    "\n",
    "Number of reviews: 568,454 Number of users: 256,059 Number of products: 74,258 Timespan: Oct 1999 - Oct 2012 Number of Attributes/Columns in data: 10\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1.  index\n",
    "2.  Id\n",
    "3.  ProductId - unique identifier for the product\n",
    "4.  UserId - unqiue identifier for the user\n",
    "5.  ProfileName\n",
    "6.  HelpfulnessNumerator - number of users who found the review helpful\n",
    "7.  HelpfulnessDenominator - number of users who indicated whether they found the review helpful or not\n",
    "8.  Score - rating between 1 and 5\n",
    "9.  Time - timestamp for the review\n",
    "10. Summary - brief summary of the review\n",
    "11. Text - text of the review\n",
    "12. ProcessedText - Cleaned & Preprocessed Text of the review\n",
    "\n",
    "**Objective: Given Amazon Food reviews, convert all the reviews into a vector by taking 5000 data points using three techniques: **<br>\n",
    "**1. BoW.**<br>\n",
    "**2. TFIDF.**<br>\n",
    "**3. Average W2V.**<br>\n",
    "\n",
    "**Then perform following tasks under each technique:**<br>\n",
    "**Task 1. Apply Hierarchical Clustering with 5 clusters.**<br>\n",
    "**Task 2. Apply Hierarchical Clustering with 15 clusters.**<br>\n",
    "**Task 3. Apply Hierarchical Clustering with 25 clusters.**<br>\n",
    "**Task 4. Apply Hierarchical Clustering with 35 clusters.**<br>\n",
    "**Task 5. Apply Hierarchical Clustering with 50 clusters.**<br>\n",
    "\n",
    "[Q] How to determine if a review is positive or negative?\n",
    "\n",
    "[Ans] We could use the Score/Rating. A rating of 4 or 5 could be cosnidered a positive review. A review of 1 or 2 could be considered negative. A review of 3 is nuetral and ignored. This is an approximate and proxy way of determining the polarity (positivity/negativity) of a review.\n",
    "\n",
    "Loading the data\n",
    "\n",
    "SQLite Database\n",
    "\n",
    "In order to load the data, We have used the SQLITE dataset as it easier to query the data and visualise the data efficiently. Here as we only want to get the global sentiment of the recommendations (positive or negative), we will purposefully ignore all Scores equal to 3. If the score id above 3, then the recommendation wil be set to \"positive\". Otherwise, it will be set to \"negative\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GauravP\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = sqlite3.connect(\"FinalAmazonFoodReviewsDataset.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_sql_query(\"SELECT * FROM Reviews\", connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>ProcessedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>have bought sever the vital can dog food produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arriv label jumbo salt peanut the pean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>this confect that has been around few centuri ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffi great price there was wide assort ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>ADT0SRK1MGOEU</td>\n",
       "      <td>Twoapennything</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1342051200</td>\n",
       "      <td>Nice Taffy</td>\n",
       "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
       "      <td>got wild hair for taffi and order this five po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Id   ProductId          UserId                      ProfileName  \\\n",
       "0      0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1      1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2      2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3      4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "4      5   6  B006K2ZZ7K   ADT0SRK1MGOEU                   Twoapennything   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "0                     1                       1  Positive  1303862400   \n",
       "1                     0                       0  Negative  1346976000   \n",
       "2                     1                       1  Positive  1219017600   \n",
       "3                     0                       0  Positive  1350777600   \n",
       "4                     0                       0  Positive  1342051200   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "4             Nice Taffy  I got a wild hair for taffy and ordered this f...   \n",
       "\n",
       "                                       ProcessedText  \n",
       "0  have bought sever the vital can dog food produ...  \n",
       "1  product arriv label jumbo salt peanut the pean...  \n",
       "2  this confect that has been around few centuri ...  \n",
       "3  great taffi great price there was wide assort ...  \n",
       "4  got wild hair for taffi and order this five po...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    307061\n",
       "Negative     57110\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Score\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changingScores(score):\n",
    "    if score == \"Positive\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing score\n",
    "# Positive = 1\n",
    "# Negative = 0\n",
    "actualScore = list(data[\"Score\"])                                                                                         \n",
    "positiveNegative = list(map(changingScores, actualScore)) #map(function, list of numbers)\n",
    "data['Score'] = positiveNegative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>ProcessedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>have bought sever the vital can dog food produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arriv label jumbo salt peanut the pean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>this confect that has been around few centuri ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffi great price there was wide assort ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>ADT0SRK1MGOEU</td>\n",
       "      <td>Twoapennything</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1342051200</td>\n",
       "      <td>Nice Taffy</td>\n",
       "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
       "      <td>got wild hair for taffi and order this five po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Id   ProductId          UserId                      ProfileName  \\\n",
       "0      0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1      1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2      2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3      4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "4      5   6  B006K2ZZ7K   ADT0SRK1MGOEU                   Twoapennything   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      1  1303862400   \n",
       "1                     0                       0      0  1346976000   \n",
       "2                     1                       1      1  1219017600   \n",
       "3                     0                       0      1  1350777600   \n",
       "4                     0                       0      1  1342051200   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "4             Nice Taffy  I got a wild hair for taffy and ordered this f...   \n",
       "\n",
       "                                       ProcessedText  \n",
       "0  have bought sever the vital can dog food produ...  \n",
       "1  product arriv label jumbo salt peanut the pean...  \n",
       "2  this confect that has been around few centuri ...  \n",
       "3  great taffi great price there was wide assort ...  \n",
       "4  got wild hair for taffi and order this five po...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking 5000 random samples\n",
    "data = data.sample(n = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4211\n",
       "0     789\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Score\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Labels = data[\"Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 12)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "print(Data.shape)\n",
    "print(Data_Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>ProcessedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280928</th>\n",
       "      <td>406309</td>\n",
       "      <td>439383</td>\n",
       "      <td>B00008434F</td>\n",
       "      <td>A3RPL2RYFV2HVZ</td>\n",
       "      <td>J. Kasper \"Crazy cat woman\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1162080000</td>\n",
       "      <td>My two cats really enjoy the Au Jus cans</td>\n",
       "      <td>Unlike the previous reviewer, my cats like the...</td>\n",
       "      <td>unlik the previous review cat like the jus can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347979</th>\n",
       "      <td>503037</td>\n",
       "      <td>543961</td>\n",
       "      <td>B006MONQMC</td>\n",
       "      <td>A1V1EP514B5H7Y</td>\n",
       "      <td>asiana</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1339459200</td>\n",
       "      <td>Is it preferable to plain water?  I think not.</td>\n",
       "      <td>I think the company that manufactures this ite...</td>\n",
       "      <td>think the compani that manufactur this item co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188179</th>\n",
       "      <td>265466</td>\n",
       "      <td>287759</td>\n",
       "      <td>B00032KL1I</td>\n",
       "      <td>A3P86MWNBD0H4K</td>\n",
       "      <td>Ameraida Lomelli</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1326758400</td>\n",
       "      <td>Great buy</td>\n",
       "      <td>It is useful to know I can count on your produ...</td>\n",
       "      <td>use know can count your product save day the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349521</th>\n",
       "      <td>504976</td>\n",
       "      <td>546033</td>\n",
       "      <td>B000EH0RTS</td>\n",
       "      <td>A2OTQ9QOJHXEY9</td>\n",
       "      <td>Susan Chamberlin \"suecalm\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1233446400</td>\n",
       "      <td>Excellent price</td>\n",
       "      <td>I've been purchasing this rice for years from ...</td>\n",
       "      <td>ive been purchas this rice for year from diffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304346</th>\n",
       "      <td>438207</td>\n",
       "      <td>473879</td>\n",
       "      <td>B001QXYZ4M</td>\n",
       "      <td>AJLW1DZSHOVGW</td>\n",
       "      <td>Elaine Campbell \"Desert Dweller\"</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1290902400</td>\n",
       "      <td>A Mildly Sweet Nutty Flavor - Delicioso!</td>\n",
       "      <td>I tasted millet a long time ago and didn't lik...</td>\n",
       "      <td>tast millet long time ago and didnt like howev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index      Id   ProductId          UserId  \\\n",
       "280928  406309  439383  B00008434F  A3RPL2RYFV2HVZ   \n",
       "347979  503037  543961  B006MONQMC  A1V1EP514B5H7Y   \n",
       "188179  265466  287759  B00032KL1I  A3P86MWNBD0H4K   \n",
       "349521  504976  546033  B000EH0RTS  A2OTQ9QOJHXEY9   \n",
       "304346  438207  473879  B001QXYZ4M   AJLW1DZSHOVGW   \n",
       "\n",
       "                             ProfileName  HelpfulnessNumerator  \\\n",
       "280928       J. Kasper \"Crazy cat woman\"                     0   \n",
       "347979                            asiana                     0   \n",
       "188179                  Ameraida Lomelli                     0   \n",
       "349521        Susan Chamberlin \"suecalm\"                     0   \n",
       "304346  Elaine Campbell \"Desert Dweller\"                     6   \n",
       "\n",
       "        HelpfulnessDenominator  Score        Time  \\\n",
       "280928                       0      1  1162080000   \n",
       "347979                       0      0  1339459200   \n",
       "188179                       0      1  1326758400   \n",
       "349521                       0      1  1233446400   \n",
       "304346                       6      1  1290902400   \n",
       "\n",
       "                                               Summary  \\\n",
       "280928        My two cats really enjoy the Au Jus cans   \n",
       "347979  Is it preferable to plain water?  I think not.   \n",
       "188179                                       Great buy   \n",
       "349521                                 Excellent price   \n",
       "304346        A Mildly Sweet Nutty Flavor - Delicioso!   \n",
       "\n",
       "                                                     Text  \\\n",
       "280928  Unlike the previous reviewer, my cats like the...   \n",
       "347979  I think the company that manufactures this ite...   \n",
       "188179  It is useful to know I can count on your produ...   \n",
       "349521  I've been purchasing this rice for years from ...   \n",
       "304346  I tasted millet a long time ago and didn't lik...   \n",
       "\n",
       "                                            ProcessedText  \n",
       "280928  unlik the previous review cat like the jus can...  \n",
       "347979  think the compani that manufactur this item co...  \n",
       "188179  use know can count your product save day the p...  \n",
       "349521  ive been purchas this rice for year from diffe...  \n",
       "304346  tast millet long time ago and didnt like howev...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "Data_BoW = count_vect.fit_transform(Data[\"ProcessedText\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(5000, 9757)\n"
     ]
    }
   ],
   "source": [
    "print(type(Data_BoW))\n",
    "print(Data_BoW.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 9757)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GauravP\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Standardizing our data matrix\n",
    "Data_BoW_Std = StandardScaler(with_mean = False).fit_transform(Data_BoW)\n",
    "print(Data_BoW_Std.shape)\n",
    "print(type(Data_BoW_Std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Apply Hierarchical Clustering with 5 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust = AgglomerativeClustering(n_clusters=5, affinity='euclidean')\n",
    "clust_fit = clust.fit(Data_BoW_Std.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has length 4996\n",
      "Cluster 1 has length 1\n",
      "Cluster 2 has length 1\n",
      "Cluster 3 has length 1\n",
      "Cluster 4 has length 1\n"
     ]
    }
   ],
   "source": [
    "Cluster_indices = {i: np.where(clust.labels_ == i) for i in range(clust.n_clusters)}\n",
    "\n",
    "for i in range(5):\n",
    "    length = len(Cluster_indices[i][0])\n",
    "    print(\"Cluster \"+str(i)+\" has length \"+str(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score = 0.6767017359815775\n"
     ]
    }
   ],
   "source": [
    "SilhouetteScore = silhouette_score(Data_BoW_Std.toarray(), clust.labels_)\n",
    "print(\"Silhouette Score = \"+str(SilhouetteScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silhouette Score of 0.676 indicates that clusters are well separated and points are assigned to correct clusters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Apply Hierarchical Clustering with 15 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has length 2\n",
      "Cluster 1 has length 1\n",
      "Cluster 2 has length 4985\n",
      "Cluster 3 has length 1\n",
      "Cluster 4 has length 1\n",
      "Cluster 5 has length 1\n",
      "Cluster 6 has length 1\n",
      "Cluster 7 has length 1\n",
      "Cluster 8 has length 1\n",
      "Cluster 9 has length 1\n",
      "Cluster 10 has length 1\n",
      "Cluster 11 has length 1\n",
      "Cluster 12 has length 1\n",
      "Cluster 13 has length 1\n",
      "Cluster 14 has length 1\n",
      "Silhouette Score = 0.6403668196634671\n"
     ]
    }
   ],
   "source": [
    "clust = AgglomerativeClustering(n_clusters=15, affinity='euclidean')\n",
    "clust_fit = clust.fit(Data_BoW_Std.toarray())\n",
    "\n",
    "Cluster_indices = {i: np.where(clust.labels_ == i) for i in range(clust.n_clusters)}\n",
    "for i in range(15):\n",
    "    length = len(Cluster_indices[i][0])\n",
    "    print(\"Cluster \"+str(i)+\" has length \"+str(length))\n",
    "    \n",
    "SilhouetteScore = silhouette_score(Data_BoW_Std.toarray(), clust.labels_)\n",
    "print(\"Silhouette Score = \"+str(SilhouetteScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silhouette Score of 0.64 indicates that clusters are well separated and points are assigned to correct clusters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Apply Hierarchical Clustering with 25 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has length 67\n",
      "Cluster 1 has length 4909\n",
      "Cluster 2 has length 2\n",
      "Cluster 3 has length 1\n",
      "Cluster 4 has length 1\n",
      "Cluster 5 has length 1\n",
      "Cluster 6 has length 1\n",
      "Cluster 7 has length 1\n",
      "Cluster 8 has length 1\n",
      "Cluster 9 has length 1\n",
      "Cluster 10 has length 1\n",
      "Cluster 11 has length 1\n",
      "Cluster 12 has length 1\n",
      "Cluster 13 has length 1\n",
      "Cluster 14 has length 1\n",
      "Cluster 15 has length 1\n",
      "Cluster 16 has length 1\n",
      "Cluster 17 has length 1\n",
      "Cluster 18 has length 1\n",
      "Cluster 19 has length 1\n",
      "Cluster 20 has length 1\n",
      "Cluster 21 has length 1\n",
      "Cluster 22 has length 1\n",
      "Cluster 23 has length 1\n",
      "Cluster 24 has length 1\n",
      "Silhouette Score = 0.5643914062554746\n"
     ]
    }
   ],
   "source": [
    "clust = AgglomerativeClustering(n_clusters=25, affinity='euclidean')\n",
    "clust_fit = clust.fit(Data_BoW_Std.toarray())\n",
    "\n",
    "Cluster_indices = {i: np.where(clust.labels_ == i) for i in range(clust.n_clusters)}\n",
    "for i in range(25):\n",
    "    length = len(Cluster_indices[i][0])\n",
    "    print(\"Cluster \"+str(i)+\" has length \"+str(length))\n",
    "    \n",
    "SilhouetteScore = silhouette_score(Data_BoW_Std.toarray(), clust.labels_)\n",
    "print(\"Silhouette Score = \"+str(SilhouetteScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silhouette Score of 0.56 indicates that clusters are well separated and points are assigned to correct clusters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4. Apply Hierarchical Clustering with 35 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has length 2\n",
      "Cluster 1 has length 4909\n",
      "Cluster 2 has length 56\n",
      "Cluster 3 has length 2\n",
      "Cluster 4 has length 1\n",
      "Cluster 5 has length 1\n",
      "Cluster 6 has length 1\n",
      "Cluster 7 has length 1\n",
      "Cluster 8 has length 1\n",
      "Cluster 9 has length 1\n",
      "Cluster 10 has length 1\n",
      "Cluster 11 has length 1\n",
      "Cluster 12 has length 1\n",
      "Cluster 13 has length 1\n",
      "Cluster 14 has length 1\n",
      "Cluster 15 has length 1\n",
      "Cluster 16 has length 1\n",
      "Cluster 17 has length 1\n",
      "Cluster 18 has length 1\n",
      "Cluster 19 has length 1\n",
      "Cluster 20 has length 1\n",
      "Cluster 21 has length 1\n",
      "Cluster 22 has length 1\n",
      "Cluster 23 has length 1\n",
      "Cluster 24 has length 1\n",
      "Cluster 25 has length 1\n",
      "Cluster 26 has length 1\n",
      "Cluster 27 has length 1\n",
      "Cluster 28 has length 1\n",
      "Cluster 29 has length 1\n",
      "Cluster 30 has length 1\n",
      "Cluster 31 has length 1\n",
      "Cluster 32 has length 1\n",
      "Cluster 33 has length 1\n",
      "Cluster 34 has length 1\n",
      "Silhouette Score = 0.5578548337794692\n"
     ]
    }
   ],
   "source": [
    "clust = AgglomerativeClustering(n_clusters=35, affinity='euclidean')\n",
    "clust_fit = clust.fit(Data_BoW_Std.toarray())\n",
    "\n",
    "Cluster_indices = {i: np.where(clust.labels_ == i) for i in range(clust.n_clusters)}\n",
    "for i in range(35):\n",
    "    length = len(Cluster_indices[i][0])\n",
    "    print(\"Cluster \"+str(i)+\" has length \"+str(length))\n",
    "    \n",
    "SilhouetteScore = silhouette_score(Data_BoW_Std.toarray(), clust.labels_)\n",
    "print(\"Silhouette Score = \"+str(SilhouetteScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silhouette Score of 0.557 indicates that clusters are well separated and points are assigned to correct clusters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5. Apply Hierarchical Clustering with 50 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has length 42\n",
      "Cluster 1 has length 4909\n",
      "Cluster 2 has length 1\n",
      "Cluster 3 has length 2\n",
      "Cluster 4 has length 1\n",
      "Cluster 5 has length 1\n",
      "Cluster 6 has length 1\n",
      "Cluster 7 has length 1\n",
      "Cluster 8 has length 1\n",
      "Cluster 9 has length 1\n",
      "Cluster 10 has length 1\n",
      "Cluster 11 has length 1\n",
      "Cluster 12 has length 1\n",
      "Cluster 13 has length 1\n",
      "Cluster 14 has length 1\n",
      "Cluster 15 has length 1\n",
      "Cluster 16 has length 1\n",
      "Cluster 17 has length 1\n",
      "Cluster 18 has length 1\n",
      "Cluster 19 has length 1\n",
      "Cluster 20 has length 1\n",
      "Cluster 21 has length 1\n",
      "Cluster 22 has length 1\n",
      "Cluster 23 has length 1\n",
      "Cluster 24 has length 1\n",
      "Cluster 25 has length 1\n",
      "Cluster 26 has length 1\n",
      "Cluster 27 has length 1\n",
      "Cluster 28 has length 1\n",
      "Cluster 29 has length 1\n",
      "Cluster 30 has length 1\n",
      "Cluster 31 has length 1\n",
      "Cluster 32 has length 1\n",
      "Cluster 33 has length 1\n",
      "Cluster 34 has length 1\n",
      "Cluster 35 has length 1\n",
      "Cluster 36 has length 1\n",
      "Cluster 37 has length 1\n",
      "Cluster 38 has length 1\n",
      "Cluster 39 has length 1\n",
      "Cluster 40 has length 1\n",
      "Cluster 41 has length 1\n",
      "Cluster 42 has length 1\n",
      "Cluster 43 has length 1\n",
      "Cluster 44 has length 1\n",
      "Cluster 45 has length 1\n",
      "Cluster 46 has length 1\n",
      "Cluster 47 has length 1\n",
      "Cluster 48 has length 1\n",
      "Cluster 49 has length 1\n",
      "Silhouette Score = 0.5483658373120096\n"
     ]
    }
   ],
   "source": [
    "clust = AgglomerativeClustering(n_clusters=50, affinity='euclidean')\n",
    "clust_fit = clust.fit(Data_BoW_Std.toarray())\n",
    "\n",
    "Cluster_indices = {i: np.where(clust.labels_ == i) for i in range(clust.n_clusters)}\n",
    "for i in range(50):\n",
    "    length = len(Cluster_indices[i][0])\n",
    "    print(\"Cluster \"+str(i)+\" has length \"+str(length))\n",
    "    \n",
    "SilhouetteScore = silhouette_score(Data_BoW_Std.toarray(), clust.labels_)\n",
    "print(\"Silhouette Score = \"+str(SilhouetteScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silhouette Score of 0.548 indicates that clusters are well separated and points are assigned to correct clusters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(ngram_range = (1, 1))\n",
    "Data_TFIDF = tfidf_vect.fit_transform(Data[\"ProcessedText\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(5000, 9576)\n"
     ]
    }
   ],
   "source": [
    "print(type(Data_TFIDF))\n",
    "print(Data_TFIDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 9576)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "Data_TFIDF_Std = StandardScaler(with_mean = False).fit_transform(Data_TFIDF)\n",
    "print(Data_TFIDF_Std.shape)\n",
    "print(type(Data_TFIDF_Std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Apply Hierarchical Clustering with 5 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has length 4996\n",
      "Cluster 1 has length 1\n",
      "Cluster 2 has length 1\n",
      "Cluster 3 has length 1\n",
      "Cluster 4 has length 1\n",
      "Silhouette Score = 0.6257186943973753\n"
     ]
    }
   ],
   "source": [
    "clust = AgglomerativeClustering(n_clusters=5, affinity='euclidean')\n",
    "clust_fit = clust.fit(Data_TFIDF_Std.toarray())\n",
    "\n",
    "Cluster_indices = {i: np.where(clust.labels_ == i) for i in range(clust.n_clusters)}\n",
    "for i in range(5):\n",
    "    length = len(Cluster_indices[i][0])\n",
    "    print(\"Cluster \"+str(i)+\" has length \"+str(length))\n",
    "    \n",
    "SilhouetteScore = silhouette_score(Data_TFIDF_Std.toarray(), clust.labels_)\n",
    "print(\"Silhouette Score = \"+str(SilhouetteScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silhouette Score of 0.625 indicates that clusters are well separated and points are assigned to correct clusters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Apply Hierarchical Clustering with 15 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has length 4985\n",
      "Cluster 1 has length 2\n",
      "Cluster 2 has length 1\n",
      "Cluster 3 has length 1\n",
      "Cluster 4 has length 1\n",
      "Cluster 5 has length 1\n",
      "Cluster 6 has length 1\n",
      "Cluster 7 has length 1\n",
      "Cluster 8 has length 1\n",
      "Cluster 9 has length 1\n",
      "Cluster 10 has length 1\n",
      "Cluster 11 has length 1\n",
      "Cluster 12 has length 1\n",
      "Cluster 13 has length 1\n",
      "Cluster 14 has length 1\n",
      "Silhouette Score = 0.5397361831622534\n"
     ]
    }
   ],
   "source": [
    "clust = AgglomerativeClustering(n_clusters=15, affinity='euclidean')\n",
    "clust_fit = clust.fit(Data_TFIDF_Std.toarray())\n",
    "\n",
    "Cluster_indices = {i: np.where(clust.labels_ == i) for i in range(clust.n_clusters)}\n",
    "for i in range(15):\n",
    "    length = len(Cluster_indices[i][0])\n",
    "    print(\"Cluster \"+str(i)+\" has length \"+str(length))\n",
    "    \n",
    "SilhouetteScore = silhouette_score(Data_TFIDF_Std.toarray(), clust.labels_)\n",
    "print(\"Silhouette Score = \"+str(SilhouetteScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silhouette Score of 0.5397 indicates that clusters are well separated and points are assigned to correct clusters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Apply Hierarchical Clustering with 25 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has length 3\n",
      "Cluster 1 has length 2\n",
      "Cluster 2 has length 4972\n",
      "Cluster 3 has length 2\n",
      "Cluster 4 has length 1\n",
      "Cluster 5 has length 1\n",
      "Cluster 6 has length 1\n",
      "Cluster 7 has length 1\n",
      "Cluster 8 has length 1\n",
      "Cluster 9 has length 1\n",
      "Cluster 10 has length 1\n",
      "Cluster 11 has length 1\n",
      "Cluster 12 has length 1\n",
      "Cluster 13 has length 1\n",
      "Cluster 14 has length 1\n",
      "Cluster 15 has length 1\n",
      "Cluster 16 has length 1\n",
      "Cluster 17 has length 1\n",
      "Cluster 18 has length 1\n",
      "Cluster 19 has length 1\n",
      "Cluster 20 has length 1\n",
      "Cluster 21 has length 1\n",
      "Cluster 22 has length 1\n",
      "Cluster 23 has length 1\n",
      "Cluster 24 has length 1\n",
      "Silhouette Score = 0.506850787992766\n"
     ]
    }
   ],
   "source": [
    "clust = AgglomerativeClustering(n_clusters=25, affinity='euclidean')\n",
    "clust_fit = clust.fit(Data_TFIDF_Std.toarray())\n",
    "\n",
    "Cluster_indices = {i: np.where(clust.labels_ == i) for i in range(clust.n_clusters)}\n",
    "for i in range(25):\n",
    "    length = len(Cluster_indices[i][0])\n",
    "    print(\"Cluster \"+str(i)+\" has length \"+str(length))\n",
    "    \n",
    "SilhouetteScore = silhouette_score(Data_TFIDF_Std.toarray(), clust.labels_)\n",
    "print(\"Silhouette Score = \"+str(SilhouetteScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silhouette Score of 0.5068 indicates that clusters are well separated and points are assigned to correct clusters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4. Apply Hierarchical Clustering with 35 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has length 4963\n",
      "Cluster 1 has length 2\n",
      "Cluster 2 has length 2\n",
      "Cluster 3 has length 2\n",
      "Cluster 4 has length 1\n",
      "Cluster 5 has length 1\n",
      "Cluster 6 has length 1\n",
      "Cluster 7 has length 1\n",
      "Cluster 8 has length 1\n",
      "Cluster 9 has length 1\n",
      "Cluster 10 has length 1\n",
      "Cluster 11 has length 1\n",
      "Cluster 12 has length 1\n",
      "Cluster 13 has length 1\n",
      "Cluster 14 has length 1\n",
      "Cluster 15 has length 1\n",
      "Cluster 16 has length 1\n",
      "Cluster 17 has length 1\n",
      "Cluster 18 has length 1\n",
      "Cluster 19 has length 1\n",
      "Cluster 20 has length 1\n",
      "Cluster 21 has length 1\n",
      "Cluster 22 has length 1\n",
      "Cluster 23 has length 1\n",
      "Cluster 24 has length 1\n",
      "Cluster 25 has length 1\n",
      "Cluster 26 has length 1\n",
      "Cluster 27 has length 1\n",
      "Cluster 28 has length 1\n",
      "Cluster 29 has length 1\n",
      "Cluster 30 has length 1\n",
      "Cluster 31 has length 1\n",
      "Cluster 32 has length 1\n",
      "Cluster 33 has length 1\n",
      "Cluster 34 has length 1\n",
      "Silhouette Score = 0.49217131235867473\n"
     ]
    }
   ],
   "source": [
    "clust = AgglomerativeClustering(n_clusters=35, affinity='euclidean')\n",
    "clust_fit = clust.fit(Data_TFIDF_Std.toarray())\n",
    "\n",
    "Cluster_indices = {i: np.where(clust.labels_ == i) for i in range(clust.n_clusters)}\n",
    "for i in range(35):\n",
    "    length = len(Cluster_indices[i][0])\n",
    "    print(\"Cluster \"+str(i)+\" has length \"+str(length))\n",
    "    \n",
    "SilhouetteScore = silhouette_score(Data_TFIDF_Std.toarray(), clust.labels_)\n",
    "print(\"Silhouette Score = \"+str(SilhouetteScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silhouette Score of 0.492 indicates that most of the clusters are well separated most of the and points are assigned to correct clusters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5. Apply Hierarchical Clustering with 50 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has length 4951\n",
      "Cluster 1 has length 1\n",
      "Cluster 2 has length 1\n",
      "Cluster 3 has length 1\n",
      "Cluster 4 has length 1\n",
      "Cluster 5 has length 1\n",
      "Cluster 6 has length 1\n",
      "Cluster 7 has length 1\n",
      "Cluster 8 has length 1\n",
      "Cluster 9 has length 1\n",
      "Cluster 10 has length 1\n",
      "Cluster 11 has length 1\n",
      "Cluster 12 has length 1\n",
      "Cluster 13 has length 1\n",
      "Cluster 14 has length 1\n",
      "Cluster 15 has length 1\n",
      "Cluster 16 has length 1\n",
      "Cluster 17 has length 1\n",
      "Cluster 18 has length 1\n",
      "Cluster 19 has length 1\n",
      "Cluster 20 has length 1\n",
      "Cluster 21 has length 1\n",
      "Cluster 22 has length 1\n",
      "Cluster 23 has length 1\n",
      "Cluster 24 has length 1\n",
      "Cluster 25 has length 1\n",
      "Cluster 26 has length 1\n",
      "Cluster 27 has length 1\n",
      "Cluster 28 has length 1\n",
      "Cluster 29 has length 1\n",
      "Cluster 30 has length 1\n",
      "Cluster 31 has length 1\n",
      "Cluster 32 has length 1\n",
      "Cluster 33 has length 1\n",
      "Cluster 34 has length 1\n",
      "Cluster 35 has length 1\n",
      "Cluster 36 has length 1\n",
      "Cluster 37 has length 1\n",
      "Cluster 38 has length 1\n",
      "Cluster 39 has length 1\n",
      "Cluster 40 has length 1\n",
      "Cluster 41 has length 1\n",
      "Cluster 42 has length 1\n",
      "Cluster 43 has length 1\n",
      "Cluster 44 has length 1\n",
      "Cluster 45 has length 1\n",
      "Cluster 46 has length 1\n",
      "Cluster 47 has length 1\n",
      "Cluster 48 has length 1\n",
      "Cluster 49 has length 1\n",
      "Silhouette Score = 0.4726919312584015\n"
     ]
    }
   ],
   "source": [
    "clust = AgglomerativeClustering(n_clusters=50, affinity='euclidean')\n",
    "clust_fit = clust.fit(Data_TFIDF_Std.toarray())\n",
    "\n",
    "Cluster_indices = {i: np.where(clust.labels_ == i) for i in range(clust.n_clusters)}\n",
    "for i in range(50):\n",
    "    length = len(Cluster_indices[i][0])\n",
    "    print(\"Cluster \"+str(i)+\" has length \"+str(length))\n",
    "    \n",
    "SilhouetteScore = silhouette_score(Data_TFIDF_Std.toarray(), clust.labels_)\n",
    "print(\"Silhouette Score = \"+str(SilhouetteScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silhouette Score of 0.472 indicates that most of the clusters are well separated most of the and points are assigned to correct clusters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVG W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "listOfSentences = []\n",
    "for sentence in Data[\"ProcessedText\"].values:\n",
    "    subSentence = []\n",
    "    for word in sentence.split():\n",
    "        subSentence.append(word)\n",
    "        \n",
    "    listOfSentences.append(subSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "they are not contain the keurig plastic cup onc you open the packag youll want put them airtight storag but was realli impress with the smooth flavor and good tast these were littl cheaper than most the keurig kcup ive found was not sure what expect but these are deff there favorit list\n",
      "\n",
      "\n",
      "[['they', 'are', 'not', 'contain', 'the', 'keurig', 'plastic', 'cup', 'onc', 'you', 'open', 'the', 'packag', 'youll', 'want', 'put', 'them', 'airtight', 'storag', 'but', 'was', 'realli', 'impress', 'with', 'the', 'smooth', 'flavor', 'and', 'good', 'tast', 'these', 'were', 'littl', 'cheaper', 'than', 'most', 'the', 'keurig', 'kcup', 'ive', 'found', 'was', 'not', 'sure', 'what', 'expect', 'but', 'these', 'are', 'deff', 'there', 'favorit', 'list'], ['who', 'has', 'time', 'make', 'your', 'own', 'filter', 'use', 'these', 'for', 'cup', 'the', 'bathroom', 'instead', 'make', 'coffe', 'with', 'them', 'wast', 'money']]\n",
      "\n",
      "\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(Data['ProcessedText'].values[0])\n",
    "print(\"\\n\")\n",
    "print(listOfSentences[0:2])\n",
    "print(\"\\n\")\n",
    "print(type(listOfSentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vModel = gensim.models.Word2Vec(listOfSentences, size=300, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "5000\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# compute average word2vec for each review.\n",
    "sentenceAsW2V = []\n",
    "for sentence in listOfSentences:\n",
    "    sentenceVector = np.zeros(300)\n",
    "    TotalWordsPerSentence = 0\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            vect = w2vModel.wv[word]\n",
    "            sentenceVector += vect\n",
    "            TotalWordsPerSentence += 1\n",
    "        except:\n",
    "            pass\n",
    "    if TotalWordsPerSentence!= 0:\n",
    "        sentenceVector /= TotalWordsPerSentence\n",
    "        sentenceAsW2V.append(sentenceVector)\n",
    "\n",
    "print(type(sentenceAsW2V))\n",
    "print(len(sentenceAsW2V))\n",
    "print(len(sentenceAsW2V[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 300)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "Data_W2V_Std = StandardScaler(with_mean = False).fit_transform(sentenceAsW2V)\n",
    "print(Data_W2V_Std.shape)\n",
    "print(type(Data_W2V_Std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Apply Hierarchical Clustering with 5 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has length 1980\n",
      "Cluster 1 has length 1266\n",
      "Cluster 2 has length 465\n",
      "Cluster 3 has length 529\n",
      "Cluster 4 has length 760\n",
      "Silhouette Score = 0.09823567463174446\n"
     ]
    }
   ],
   "source": [
    "clust = AgglomerativeClustering(n_clusters=5, affinity='euclidean')\n",
    "clust_fit = clust.fit(Data_W2V_Std)\n",
    "\n",
    "Cluster_indices = {i: np.where(clust.labels_ == i) for i in range(clust.n_clusters)}\n",
    "for i in range(5):\n",
    "    length = len(Cluster_indices[i][0])\n",
    "    print(\"Cluster \"+str(i)+\" has length \"+str(length))\n",
    "    \n",
    "SilhouetteScore = silhouette_score(Data_W2V_Std, clust.labels_)\n",
    "print(\"Silhouette Score = \"+str(SilhouetteScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silhouette Score of 0.0982 indicates that clusters are overlapped and not well separated**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Apply Hierarchical Clustering with 15 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has length 522\n",
      "Cluster 1 has length 241\n",
      "Cluster 2 has length 465\n",
      "Cluster 3 has length 500\n",
      "Cluster 4 has length 196\n",
      "Cluster 5 has length 247\n",
      "Cluster 6 has length 744\n",
      "Cluster 7 has length 214\n",
      "Cluster 8 has length 220\n",
      "Cluster 9 has length 297\n",
      "Cluster 10 has length 288\n",
      "Cluster 11 has length 243\n",
      "Cluster 12 has length 164\n",
      "Cluster 13 has length 373\n",
      "Cluster 14 has length 286\n",
      "Silhouette Score = 0.04030005211897009\n"
     ]
    }
   ],
   "source": [
    "clust = AgglomerativeClustering(n_clusters=15, affinity='euclidean')\n",
    "clust_fit = clust.fit(Data_W2V_Std)\n",
    "\n",
    "Cluster_indices = {i: np.where(clust.labels_ == i) for i in range(clust.n_clusters)}\n",
    "for i in range(15):\n",
    "    length = len(Cluster_indices[i][0])\n",
    "    print(\"Cluster \"+str(i)+\" has length \"+str(length))\n",
    "    \n",
    "SilhouetteScore = silhouette_score(Data_W2V_Std, clust.labels_)\n",
    "print(\"Silhouette Score = \"+str(SilhouetteScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silhouette Score of 0.0403 indicates that clusters are overlapped and not well separated**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Apply Hierarchical Clustering with 25 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has length 744\n",
      "Cluster 1 has length 220\n",
      "Cluster 2 has length 295\n",
      "Cluster 3 has length 122\n",
      "Cluster 4 has length 172\n",
      "Cluster 5 has length 243\n",
      "Cluster 6 has length 147\n",
      "Cluster 7 has length 170\n",
      "Cluster 8 has length 187\n",
      "Cluster 9 has length 297\n",
      "Cluster 10 has length 60\n",
      "Cluster 11 has length 125\n",
      "Cluster 12 has length 164\n",
      "Cluster 13 has length 373\n",
      "Cluster 14 has length 286\n",
      "Cluster 15 has length 169\n",
      "Cluster 16 has length 304\n",
      "Cluster 17 has length 158\n",
      "Cluster 18 has length 69\n",
      "Cluster 19 has length 196\n",
      "Cluster 20 has length 49\n",
      "Cluster 21 has length 26\n",
      "Cluster 22 has length 169\n",
      "Cluster 23 has length 92\n",
      "Cluster 24 has length 163\n",
      "Silhouette Score = 0.038586709442794166\n"
     ]
    }
   ],
   "source": [
    "clust = AgglomerativeClustering(n_clusters=25, affinity='euclidean')\n",
    "clust_fit = clust.fit(Data_W2V_Std)\n",
    "\n",
    "Cluster_indices = {i: np.where(clust.labels_ == i) for i in range(clust.n_clusters)}\n",
    "for i in range(25):\n",
    "    length = len(Cluster_indices[i][0])\n",
    "    print(\"Cluster \"+str(i)+\" has length \"+str(length))\n",
    "    \n",
    "SilhouetteScore = silhouette_score(Data_W2V_Std, clust.labels_)\n",
    "print(\"Silhouette Score = \"+str(SilhouetteScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silhouette Score of 0.0385 indicates that clusters are overlapped and not well separated**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4. Apply Hierarchical Clustering with 35 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has length 147\n",
      "Cluster 1 has length 174\n",
      "Cluster 2 has length 286\n",
      "Cluster 3 has length 187\n",
      "Cluster 4 has length 139\n",
      "Cluster 5 has length 125\n",
      "Cluster 6 has length 373\n",
      "Cluster 7 has length 169\n",
      "Cluster 8 has length 158\n",
      "Cluster 9 has length 196\n",
      "Cluster 10 has length 60\n",
      "Cluster 11 has length 163\n",
      "Cluster 12 has length 182\n",
      "Cluster 13 has length 89\n",
      "Cluster 14 has length 329\n",
      "Cluster 15 has length 72\n",
      "Cluster 16 has length 304\n",
      "Cluster 17 has length 62\n",
      "Cluster 18 has length 69\n",
      "Cluster 19 has length 253\n",
      "Cluster 20 has length 49\n",
      "Cluster 21 has length 26\n",
      "Cluster 22 has length 169\n",
      "Cluster 23 has length 92\n",
      "Cluster 24 has length 145\n",
      "Cluster 25 has length 164\n",
      "Cluster 26 has length 76\n",
      "Cluster 27 has length 121\n",
      "Cluster 28 has length 50\n",
      "Cluster 29 has length 33\n",
      "Cluster 30 has length 25\n",
      "Cluster 31 has length 82\n",
      "Cluster 32 has length 44\n",
      "Cluster 33 has length 233\n",
      "Cluster 34 has length 154\n",
      "Silhouette Score = 0.04050277449371593\n"
     ]
    }
   ],
   "source": [
    "clust = AgglomerativeClustering(n_clusters=35, affinity='euclidean')\n",
    "clust_fit = clust.fit(Data_W2V_Std)\n",
    "\n",
    "Cluster_indices = {i: np.where(clust.labels_ == i) for i in range(clust.n_clusters)}\n",
    "for i in range(35):\n",
    "    length = len(Cluster_indices[i][0])\n",
    "    print(\"Cluster \"+str(i)+\" has length \"+str(length))\n",
    "    \n",
    "SilhouetteScore = silhouette_score(Data_W2V_Std, clust.labels_)\n",
    "print(\"Silhouette Score = \"+str(SilhouetteScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silhouette Score of 0.0405 indicates that clusters are overlapped and not well separated**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5. Apply Hierarchical Clustering with 50 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 has length 162\n",
      "Cluster 1 has length 60\n",
      "Cluster 2 has length 182\n",
      "Cluster 3 has length 69\n",
      "Cluster 4 has length 196\n",
      "Cluster 5 has length 164\n",
      "Cluster 6 has length 84\n",
      "Cluster 7 has length 108\n",
      "Cluster 8 has length 139\n",
      "Cluster 9 has length 253\n",
      "Cluster 10 has length 26\n",
      "Cluster 11 has length 146\n",
      "Cluster 12 has length 76\n",
      "Cluster 13 has length 89\n",
      "Cluster 14 has length 33\n",
      "Cluster 15 has length 72\n",
      "Cluster 16 has length 233\n",
      "Cluster 17 has length 143\n",
      "Cluster 18 has length 52\n",
      "Cluster 19 has length 77\n",
      "Cluster 20 has length 49\n",
      "Cluster 21 has length 197\n",
      "Cluster 22 has length 169\n",
      "Cluster 23 has length 81\n",
      "Cluster 24 has length 145\n",
      "Cluster 25 has length 107\n",
      "Cluster 26 has length 93\n",
      "Cluster 27 has length 121\n",
      "Cluster 28 has length 50\n",
      "Cluster 29 has length 71\n",
      "Cluster 30 has length 25\n",
      "Cluster 31 has length 82\n",
      "Cluster 32 has length 44\n",
      "Cluster 33 has length 59\n",
      "Cluster 34 has length 154\n",
      "Cluster 35 has length 62\n",
      "Cluster 36 has length 63\n",
      "Cluster 37 has length 133\n",
      "Cluster 38 has length 66\n",
      "Cluster 39 has length 41\n",
      "Cluster 40 has length 132\n",
      "Cluster 41 has length 98\n",
      "Cluster 42 has length 44\n",
      "Cluster 43 has length 84\n",
      "Cluster 44 has length 87\n",
      "Cluster 45 has length 72\n",
      "Cluster 46 has length 171\n",
      "Cluster 47 has length 51\n",
      "Cluster 48 has length 70\n",
      "Cluster 49 has length 15\n",
      "Silhouette Score = 0.04023371899154547\n"
     ]
    }
   ],
   "source": [
    "clust = AgglomerativeClustering(n_clusters=50, affinity='euclidean')\n",
    "clust_fit = clust.fit(Data_W2V_Std)\n",
    "\n",
    "Cluster_indices = {i: np.where(clust.labels_ == i) for i in range(clust.n_clusters)}\n",
    "for i in range(50):\n",
    "    length = len(Cluster_indices[i][0])\n",
    "    print(\"Cluster \"+str(i)+\" has length \"+str(length))\n",
    "    \n",
    "SilhouetteScore = silhouette_score(Data_W2V_Std, clust.labels_)\n",
    "print(\"Silhouette Score = \"+str(SilhouetteScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silhouette Score of 0.0402 indicates that clusters are overlapped and not well separated**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
